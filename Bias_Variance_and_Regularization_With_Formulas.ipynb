{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5db28ac3",
   "metadata": {},
   "source": [
    "\n",
    "# Bias–Variance Tradeoff and Regularization (with Formulas)\n",
    "\n",
    "This notebook explains bias, variance, and regularization **with mathematical intuition**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fceb3c0",
   "metadata": {},
   "source": [
    "\n",
    "## Bias and Variance (Mathematical View)\n",
    "\n",
    "Let the true function be $f(x)$ and our model prediction be $\\hat{f}(x)$.\n",
    "\n",
    "The expected squared error can be decomposed as:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[(y - \\hat{f}(x))^2] =\n",
    "\\underbrace{\\text{Bias}^2}_{\\text{Error from wrong assumptions}} +\n",
    "\\underbrace{\\text{Variance}}_{\\text{Sensitivity to data}} +\n",
    "\\underbrace{\\sigma^2}_{\\text{Irreducible noise}}\n",
    "$$\n",
    "\n",
    "### Bias\n",
    "$$\n",
    "\\text{Bias} = \\mathbb{E}[\\hat{f}(x)] - f(x)\n",
    "$$\n",
    "\n",
    "### Variance\n",
    "$$\n",
    "\\text{Variance} = \\mathbb{E}[(\\hat{f}(x) - \\mathbb{E}[\\hat{f}(x)])^2]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd80d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.sort(np.random.rand(20, 1), axis=0)\n",
    "y = np.sin(2 * np.pi * X).ravel() + np.random.normal(0, 0.2, 20)\n",
    "\n",
    "degrees = [1, 4, 15]\n",
    "\n",
    "plt.figure()\n",
    "for d in degrees:\n",
    "    model = make_pipeline(PolynomialFeatures(d), LinearRegression())\n",
    "    model.fit(X, y)\n",
    "    X_test = np.linspace(0, 1, 200).reshape(-1, 1)\n",
    "    y_pred = model.predict(X_test)\n",
    "    plt.plot(X_test, y_pred, label=f\"Degree {d}\")\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.legend()\n",
    "plt.title(\"Bias–Variance Tradeoff\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ee1de",
   "metadata": {},
   "source": [
    "\n",
    "## Regularization\n",
    "\n",
    "Regularization modifies the loss function:\n",
    "\n",
    "### Ordinary Least Squares\n",
    "$$\n",
    "\\mathcal{L}_{OLS} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41acc0c",
   "metadata": {},
   "source": [
    "\n",
    "### L2 Regularization (Ridge)\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{Ridge} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{p} w_j^2\n",
    "$$\n",
    "\n",
    "- Shrinks coefficients\n",
    "- Reduces variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18945942",
   "metadata": {},
   "source": [
    "\n",
    "### L1 Regularization (Lasso)\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{Lasso} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{p} |w_j|\n",
    "$$\n",
    "\n",
    "- Produces sparse models\n",
    "- Performs feature selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf8e26",
   "metadata": {},
   "source": [
    "\n",
    "### Elastic Net (L1 + L2)\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{EN} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "+ \\lambda \\left( \\alpha \\sum |w_j| + (1-\\alpha) \\sum w_j^2 \\right)\n",
    "$$\n",
    "\n",
    "- Combines sparsity and stability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404aee50",
   "metadata": {},
   "source": [
    "\n",
    "## Effect on Bias and Variance\n",
    "\n",
    "| Method | Bias | Variance |\n",
    "|------|------|---------|\n",
    "| No regularization | Low | High |\n",
    "| Ridge | Slight ↑ | ↓ |\n",
    "| Lasso | ↑ | ↓↓ |\n",
    "| Elastic Net | Balanced | Balanced |\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
